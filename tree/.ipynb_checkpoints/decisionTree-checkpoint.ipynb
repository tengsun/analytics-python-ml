{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "import operator\n",
    "import pickle\n",
    "import treePlotter\n",
    "\n",
    "# create data to test fish\n",
    "def createDataSet():\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    return dataSet, labels\n",
    "\n",
    "# calculate shannon entropy\n",
    "def calculateEntropy(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for vector in dataSet:\n",
    "        # use last column label to calculate\n",
    "        curr = vector[-1]\n",
    "        if curr not in labelCounts.keys():\n",
    "            labelCounts[curr] = 0\n",
    "        labelCounts[curr] += 1\n",
    "    # print labelCounts\n",
    "    \n",
    "    entropy = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key]) / numEntries\n",
    "        entropy -= prob * log(prob, 2)\n",
    "        # print \"key: %s, probability: %f, log func: %f\" \\\n",
    "        #    %(key, prob, log(prob, 2))\n",
    "    return entropy\n",
    "\n",
    "dataSet, labels = createDataSet()\n",
    "calculateEntropy(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "[[1, 'no'], [1, 'no']]\n"
     ]
    }
   ],
   "source": [
    "# split data set by axis & value\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    # create new data set to avoid change on original one\n",
    "    reducedDataSet = []\n",
    "    for vector in dataSet:\n",
    "        if vector[axis] == value:\n",
    "            reducedVector = vector[:axis]\n",
    "            reducedVector.extend(vector[axis + 1:])\n",
    "            reducedDataSet.append(reducedVector)\n",
    "    return reducedDataSet\n",
    "\n",
    "reduced1 = splitDataSet(dataSet, 0, 1)\n",
    "print reduced1\n",
    "reduced2 = splitDataSet(dataSet, 0, 0)\n",
    "print reduced2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original entropy: 0.970951\n",
      "[1, 1, 1, 0, 0]\n",
      "curr index: 0, new entropy: 0.550978, reduced entropy: 0.419973\n",
      "[1, 1, 0, 1, 1]\n",
      "curr index: 1, new entropy: 0.800000, reduced entropy: 0.170951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the best split feature\n",
    "def chooseBestSplitFeature(dataSet):\n",
    "    # last column is the class label\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calculateEntropy(dataSet)\n",
    "    print \"original entropy: %f\" %(baseEntropy)\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    \n",
    "    # iterate features and calculate entropy\n",
    "    for i in range(numFeatures):\n",
    "        # convert column i data to feature array\n",
    "        featureList = [example[i] for example in dataSet]\n",
    "        # print featureList\n",
    "        # retrieve unique values of each feature\n",
    "        uniqueVals = set(featureList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob * calculateEntropy(subDataSet)\n",
    "        reducedEntropy = baseEntropy - newEntropy\n",
    "        print \"curr index: %d, new entropy: %f, reduced entropy: %f\" \\\n",
    "            %(i, newEntropy, reducedEntropy)\n",
    "        \n",
    "        if (reducedEntropy > bestInfoGain):\n",
    "            bestInfoGain = reducedEntropy\n",
    "            bestFeature = i\n",
    "    \n",
    "    return bestFeature\n",
    "\n",
    "chooseBestSplitFeature(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original entropy: 0.970951\n",
      "[1, 1, 1, 0, 0]\n",
      "curr index: 0, new entropy: 0.550978, reduced entropy: 0.419973\n",
      "[1, 1, 0, 1, 1]\n",
      "curr index: 1, new entropy: 0.800000, reduced entropy: 0.170951\n",
      "best feature is: 0 - no surfacing\n",
      "original entropy: 0.918296\n",
      "[1, 1, 0]\n",
      "curr index: 0, new entropy: 0.000000, reduced entropy: 0.918296\n",
      "best feature is: 0 - flippers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the top class in the list\n",
    "def majorityCount(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), \n",
    "        key = operator.itemgetter(1), reverse = True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "# input data set and feature labels\n",
    "def createTree(dataSet, featureLabels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    \n",
    "    # stop and return if all classes are the same\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    \n",
    "    # check if all the features have been used up\n",
    "    # return majority class in case not classified\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCount(classList)\n",
    "    \n",
    "    # select best feature and label\n",
    "    bestFeature = chooseBestSplitFeature(dataSet)\n",
    "    bestFeatureLabel = featureLabels[bestFeature]\n",
    "    print 'best feature is: %d - %s' % (bestFeature, bestFeatureLabel)\n",
    "    myTree = {bestFeatureLabel: {}}\n",
    "    \n",
    "    del(featureLabels[bestFeature])\n",
    "    featureValues = [example[bestFeature] for example in dataSet]\n",
    "    uniqueValues = set(featureValues)\n",
    "    for value in uniqueValues:\n",
    "        subLabels = featureLabels[:]\n",
    "        \n",
    "        # iterate to construct sub-trees\n",
    "        myTree[bestFeatureLabel][value] = \\\n",
    "            createTree(splitDataSet(dataSet, bestFeature, value), subLabels)\n",
    "    \n",
    "    return myTree\n",
    "\n",
    "dataSet, labels = createDataSet()\n",
    "myTree = createTree(dataSet, labels)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classification using decision tree algorithm\n",
    "# featureLabels and testVector are consistent\n",
    "def classify(inputTree, featureLabels, testVector):\n",
    "    currKey = inputTree.keys()[0]\n",
    "    currDict = inputTree[currKey]\n",
    "    \n",
    "    # get correct feature index by current key\n",
    "    featureIndex = featureLabels.index(currKey)\n",
    "    for key in currDict.keys():\n",
    "        if testVector[featureIndex] == key:\n",
    "            if type(currDict[key]).__name__ == 'dict':\n",
    "                classLabel = classify(currDict[key], featureLabels, testVector)\n",
    "            else:\n",
    "                classLabel = currDict[key]\n",
    "    return classLabel\n",
    "\n",
    "# store tree to local file\n",
    "def storeTree(inputTree, filename):\n",
    "    fw = open(filename, 'w')\n",
    "    pickle.dump(inputTree, fw)\n",
    "    fw.close()\n",
    "\n",
    "# restore tree from local file\n",
    "def grabTree(filename):\n",
    "    fr = open(filename)\n",
    "    return pickle.load(fr)\n",
    "\n",
    "## lenses doctor query test\n",
    "def checkLenses():\n",
    "    fr = open('data/lenses.txt')\n",
    "    lenses = [line.strip().split('\\t') for line in fr.readlines()]\n",
    "    lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "    lensesTree = createTree(lenses, lensesLabels)\n",
    "    print lensesTree\n",
    "    treePlotter.createPlot(lensesTree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
